# Сравнение классических и модернизированных подходов сети LeNet-5

Проект исследует **генерацию** и распознавание синтетических изображений цифр из различных числовых систем (западные, восточноарабские, римские) с использованием разнообразных техник аугментации данных. Мы сравниваем две модели: **классическую LeNet-5** и **актуализированную версию** с современными практиками глубокого обучения.

---

## Описание проекта

В этом проекте мы погружаемся в увлекательный мир распознавания цифр, выходя за рамки привычных западных чисел. Мы с нуля создаем синтетические наборы данных для цифр из **трёх различных числовых систем**:

- **Западные цифры:** 0, 1, 2, ..., 9
- **Восточноарабские цифры:** ٠, ١, ٢, ..., ٩
- **Римские цифры:** N (для нуля), I, II, ..., IX

### Основные задачи и компоненты:

1. **Генерация датасетов:** Разработан Python-скрипт для программного создания изображений цифр размером 28x28 пикселей. Это позволяет нам контролировать процесс создания данных и получать контролируемые наборы для обучения.
2. **Аугментация данных:** Для повышения реалистичности и сложности синтетических изображений применяются различные техники аугментации, включая:
    - Изменение контраста
    - Незначительные смещения
    - Повороты
    - Добавление случайного шума
    - Применение гауссова размытия
    - Включение "сложных" примеров с усиленными аугментациями и **намеренной ошибочной маркировкой** для части данных, что имитирует реальные трудности и "шум" в датасетах.
3. **Сравнительный анализ моделей распознавания:** Мы исследуем производительность двух архитектур сверточных нейронных сетей:
    - **Классическая LeNet-5:** Реализована согласно её оригинальному дизайну, используя свёртки 5x5, активации Tanh и Average Pooling.
    - **Актуализированная LeNet-подобная сеть:** Модифицированная версия, включающая современные практики глубокого обучения:
        - Замена свёрточных ядер 5x5 на стек из **двух свёрток 3x3** для лучшего захвата локальных признаков и уменьшения количества параметров.
        - Использование **активации ReLU** вместо Tanh для ускорения обучения и решения проблемы исчезающего градиента.
        - Применение **Max Pooling** вместо Average Pooling для более агрессивного снижения размерности и сохранения наиболее значимых признаков.
        - Интеграция слоёв **Batch Normalization** для стабилизации распределения активаций и ускорения сходимости сети.

---

## Структура проекта

- `digit_dataset.py`: Скрипт, отвечающий за **генерацию синтетических изображений цифр** из различных систем счисления, применение аугментаций и подготовку обучающих/тестовых наборов данных в формате PyTorch тензоров.
- `ReLeNet5.py`: Содержит определение класса нейронной сети `LeNet5` (с опциями для классической и модернизированной конфигурации), а также логику для **обучения и оценки** моделей на сгенерированных данных. Этот скрипт является основной точкой входа для запуска всего исследовательского цикла.
- `digit_dataset/`: Директория, куда сохраняются сгенерированные изображения и тензоры PyTorch для обучения и тестирования.
- `training_plots/`: Директория для графиков точности и потерь, сгенерированных в процессе обучения.
- `results_summary.csv` / `results_summary.xlsx`: Сводные таблицы результатов обучения всех конфигураций моделей.
- `results_raw.pkl`: Полные сырые результаты обучения (история точности и потерь) в формате pickle.

---

## Использование

### Требования

Для запуска проекта вам потребуется установить следующие библиотеки:

- `Pillow` (PIL)
- `NumPy`
- `PyTorch`
- `scikit-learn`
- `matplotlib`
- `pandas`

Вы можете установить их с помощью pip:

Bash

`pip install Pillow numpy torch torchvision scikit-learn matplotlib pandas`

### Запуск проекта

Для запуска всего процесса — от генерации датасетов до обучения моделей и сохранения результатов — выполните следующий скрипт:

Bash

`python ReLeNet5.py`

- **Генерация данных:** При первом запуске скрипт `digit_dataset.py` создаст необходимый набор данных в директории `digit_dataset/`. Вы можете настроить параметры генерации (например, количество образцов на цифру, долю тестовых данных, долю намеренно ошибочно размеченных "сложных" примеров и флаг сохранения изображений) в блоке `main` файла `digit_dataset.py`.
- **Обучение и анализ:** После генерации данных, `ReLeNet5.py` продолжит процесс обучения и оценки для различных конфигураций моделей (как классической, так и модернизированных версий LeNet-5) на каждом из сгенерированных датасетов.

Результаты обучения (история точности и потерь) будут сохранены в виде графиков в директории `training_plots/`, а также в сводных таблицах `results_summary.csv` и `results_summary.xlsx`.

---

## Результаты и выводы

После запуска проекта вы сможете проанализировать:

- Как классическая LeNet-5 справляется с каждым типом числовой системы.
- Насколько современные практики (ReLU, Max Pooling, Batch Normalization, свёртки 3x3) улучшают производительность и стабильность обучения по сравнению с оригинальной архитектурой.
- Влияние аугментаций и намеренной ошибочной маркировки на способность моделей к обобщению.